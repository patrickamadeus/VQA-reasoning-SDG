### Model Parameters
seed: 32
llava:
    model_name: llava-1.5-13b-hf
    model_path: llava-hf/llava-1.5-13b-hf
    model_params:
        pair_count: 15
    result:
        lr_path: ../result/inference/{model_name}/LR/
        qg_path: ../result/inference/{model_name}/QG/
        json_path: ../result/inference/{model_name}/json/
        story_path: ../result/inference/{model_name}/story/
        qgstory_path: ../result/inference/{model_name}/qgstory/
        str8_path: ../result/inference/{model_name}/str8/


### Prompting (updated)
prompt:
    lr:
        parent: ../prompt/LR/
        filename: base.txt
    qg:
        parent: ../prompt/QG/
        filename: 3W_split.txt
    str8:
        parent: ../prompt/str8/
        filename: base.txt
    qgstory:
        parent: ../prompt/qgstory/
        story_filename: story_base.txt
        qg_filename: gen_base.txt
    eval:
        parent: ../../prompt/eval/
        factoid: factoid.txt
        reasoning: reasoning.txt
        complete: complete.txt

### Image
image_path: ../dataset/sample/sample_001.jpg
image_dataset: sample
        
        
### Eval
eval:
    result_model_name: sample
    result_json: sample_24011353.json
    
    img_dir: ../dataset/{image_dataset}/
    result_dir: ../result/inference/{model_name}/json/{result_json}
    
    evaluator_model_path: llava-hf/llava-1.5-13b-hf
    factoid_prompt: ../prompt/eval/self_factoid.txt
    reasoning_prompt: ../prompt/eval/self_reasoning.txt
    r0: ../prompt/eval/self_reasoning/r0.txt
    r1: ../prompt/eval/self_reasoning/r1.txt
    r2: ../prompt/eval/self_reasoning/r2.txt
    r3: ../prompt/eval/self_reasoning/r3.txt
    r4: ../prompt/eval/self_reasoning/r4.txt
    eval_result_path: ../result/eval/
    
#     sample:
#         img_parent: ./dataset/sample/
#         json_parent: ./json/sample/
#         json_filename: sample_24011309.json
#     llava:
#         model: openai/clip-vit-base-patch32
#         json_path: ../result/LLaVa/json/
    