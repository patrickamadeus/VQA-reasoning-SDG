{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e54b3",
   "metadata": {},
   "source": [
    "# LLaVa Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f27ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def load_config(config_path,config_name):\n",
    "    with open(os.path.join(config_path, config_name)) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config(\"../\",\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe1b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample_001': 30, 'sample_007': 10, 'sample_005': 20, 'sample_009': 10, 'sample_002': 20}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "res = {}\n",
    "\n",
    "with open('sample_eval.json') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "for i in d:\n",
    "    if i['image_id'] not in res:\n",
    "        res[i['image_id']] = 1\n",
    "    else:\n",
    "        res[i['image_id']] += 1\n",
    "\n",
    "print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22dc37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants & Seed\n",
    "SEED = config[\"seed\"]\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Inputs\n",
    "IMG_PATH = config[\"image_path\"]\n",
    "IMG_ID = IMG_PATH.split('/')[-1].split('.')[0]\n",
    "\n",
    "# Prompt\n",
    "LR_PROMPT_TYPE = config['prompt']['lr']['filename']\n",
    "QG_PROMPT_TYPE = config[\"prompt\"][\"qg\"][\"filename\"]\n",
    "STR8_PROMPT_TYPE = config[\"prompt\"][\"str8\"][\"filename\"]\n",
    "STORY_PROMPT_TYPE = config[\"prompt\"][\"qgstory\"][\"story_filename\"]\n",
    "QGSTORY_PROMPT_TYPE = config[\"prompt\"][\"qgstory\"][\"qg_filename\"]\n",
    "\n",
    "LR_PROMPT_PATH = f\"{config['prompt']['lr']['parent']}{LR_PROMPT_TYPE}\"\n",
    "QG_PROMPT_PATH = f'{config[\"prompt\"][\"qg\"][\"parent\"]}{QG_PROMPT_TYPE}'\n",
    "STR8_PROMPT_PATH = f\"{config['prompt']['str8']['parent']}{STR8_PROMPT_TYPE}\"\n",
    "STORY_PROMPT_PATH = f\"{config['prompt']['qgstory']['parent']}{STORY_PROMPT_TYPE}\"\n",
    "QGSTORY_PROMPT_PATH = f\"{config['prompt']['qgstory']['parent']}{QGSTORY_PROMPT_TYPE}\"\n",
    "\n",
    "with open(LR_PROMPT_PATH, \"r\") as file:\n",
    "    LR_PROMPT= file.read()\n",
    "with open(QG_PROMPT_PATH,\"r\") as file:\n",
    "    QG_PROMPT = file.read()\n",
    "with open(STR8_PROMPT_PATH,\"r\") as file:\n",
    "    STR8_PROMPT = file.read()\n",
    "with open(STORY_PROMPT_PATH,\"r\") as file:\n",
    "    STORY_PROMPT = file.read()\n",
    "with open(QGSTORY_PROMPT_PATH,\"r\") as file:\n",
    "    QGSTORY_PROMPT = file.read()\n",
    "\n",
    "# Params\n",
    "MODEL_NAME = config[\"llava\"][\"model_name\"]\n",
    "MODEL_PATH = config[\"llava\"][\"model_path\"]\n",
    "PAIR_NUM = config[\"llava\"][\"model_params\"][\"pair_count\"]\n",
    "\n",
    "# Result\n",
    "LR_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"lr_path\"].format(model_name = MODEL_NAME)\n",
    "QG_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"qg_path\"].format(model_name = MODEL_NAME)\n",
    "JSON_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"json_path\"].format(model_name = MODEL_NAME)\n",
    "STORY_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"story_path\"].format(model_name = MODEL_NAME)\n",
    "QGSTORY_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"qgstory_path\"].format(model_name = MODEL_NAME)\n",
    "STR8_RESULT_PARENT_PATH = config[\"llava\"][\"result\"][\"str8_path\"].format(model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464479b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mistral_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.52it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import transformers\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "transformers.set_seed(SEED)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    MODEL_PATH, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    "#     load_in_4bit=True\n",
    ").to(0)\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc708ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_llava(model, processor, prompt, img, max_new_tokens=1500, do_sample=False, skip_special_tokens=True) -> str:\n",
    "    complete_prompt = f\"USER: <image>\\n{prompt}\\nASSISTANT:\"\n",
    "    \n",
    "    inputs = processor(\n",
    "        complete_prompt, \n",
    "        img, \n",
    "        return_tensors = 'pt'\n",
    "    ).to(0, torch.float16)\n",
    "    \n",
    "    raw_output = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens = max_new_tokens, \n",
    "        do_sample = do_sample\n",
    "    )\n",
    "    \n",
    "    output = processor.decode(raw_output[0], skip_special_tokens = skip_special_tokens)\n",
    "    output_trunc = output[output.index(\"ASSISTANT:\") + 11:]\n",
    "    \n",
    "    return output_trunc\n",
    "\n",
    "def exec_time(to, tt) -> str:\n",
    "    time_difference = tt - to\n",
    "\n",
    "    hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    result_format = f\"{hours}h{minutes}m{seconds}s\"\n",
    "    \n",
    "    return result_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44382cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "raw_image = Image.open(IMG_PATH)\n",
    "\n",
    "# t_lrqg_o = datetime.now()\n",
    "# lr_out = inference_llava(\n",
    "#     model, processor, \n",
    "#     LR_PROMPT.format(number = PAIR_NUM), \n",
    "#     raw_image\n",
    "# )\n",
    "\n",
    "# qg_out = inference_llava(\n",
    "#     model, processor,\n",
    "#     QG_PROMPT.format(desc = lr_out, number = PAIR_NUM),\n",
    "#     raw_image\n",
    "# )\n",
    "# t_lrqg_t = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "# t_str8_o = datetime.now()\n",
    "# str8_out = inference_llava(\n",
    "#     model, processor,\n",
    "#     STR8_PROMPT.format(number = PAIR_NUM),\n",
    "#     raw_image\n",
    "# )\n",
    "# t_str8_t = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "t_qgstory_o = datetime.now()\n",
    "story_out = inference_llava(\n",
    "    model, processor,\n",
    "    STORY_PROMPT,\n",
    "    raw_image\n",
    ")\n",
    "\n",
    "qgstory_out = inference_llava(\n",
    "    model, processor,\n",
    "    QGSTORY_PROMPT.format(story = story_out, number = PAIR_NUM),\n",
    "    raw_image\n",
    ")\n",
    "t_qgstory_t = datetime.now()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%m_%d_%Y-%H:%M:%S\")\n",
    "# lrqg_exec_time = exec_time(t_lrqg_o, t_lrqg_t)\n",
    "# qgstory_exec_time = exec_time(t_qgstory_o, t_qgstory_t)\n",
    "# str8_exec_time = exec_time(t_str8_t, t_str8_t)\n",
    "qgstory_exec_time = exec_time(t_qgstory_o, t_qgstory_t)\n",
    "\n",
    "\n",
    "\n",
    "FILENAME = f\"{IMG_ID}_{timestamp}.txt\" \n",
    "LR_RESULT_PATH = LR_RESULT_PARENT_PATH + FILENAME\n",
    "QG_RESULT_PATH = QG_RESULT_PARENT_PATH + FILENAME\n",
    "STORY_RESULT_PATH = STORY_RESULT_PARENT_PATH + FILENAME\n",
    "QGSTORY_RESULT_PATH = QGSTORY_RESULT_PARENT_PATH + FILENAME\n",
    "STR8_RESULT_PATH = STR8_RESULT_PARENT_PATH + FILENAME\n",
    "\n",
    "\n",
    "# with open(LR_RESULT_PATH,\"w\") as f:\n",
    "#     f.write(lr_out)\n",
    "# with open(QG_RESULT_PATH,\"w\") as f:\n",
    "#     f.write(qg_out)\n",
    "#     f.write(\"\\n\\n\")\n",
    "#     f.write(lrqg_exec_time)\n",
    "# with open(STORY_RESULT_PATH,\"w\") as f:\n",
    "#     f.write(story_out)\n",
    "#     f.write(\"\\n\\n\")\n",
    "#     f.write(lrqg_exec_time)\n",
    "# with open(QGSTORY_RESULT_PATH,\"w\") as f:\n",
    "#     f.write(qgstory_out)\n",
    "#     f.write(\"\\n\\n\")\n",
    "#     f.write(qgstory_exec_time)\n",
    "# with open(STR8_RESULT_PATH,\"w\") as f:\n",
    "#     f.write(str8_out)\n",
    "#     f.write(\"\\n\\n\")\n",
    "#     f.write(str8_exec_time)\n",
    "\n",
    "with open(\"sample_0012_qgstory.txt\",\"w\") as f:\n",
    "    f.write(qgstory_out)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(qgstory_exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2a1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_inference(image_path, model, processor, total_pair_count, pair_per_batch = 10):\n",
    "    raw_image = Image.open(image_path)\n",
    "\n",
    "    NUM_BATCH = ceil(total_pair_count / pair_per_batch)\n",
    "    LAST_BATCH = total_pair_count % pair_per_batch\n",
    "    \n",
    "    total_out = \"\"\n",
    "    \n",
    "    for batch in tqdm(range(NUM_BATCH)):\n",
    "        if batch == NUM_BATCH - 1:\n",
    "            pair_per_batch = LAST_BATCH\n",
    "\n",
    "        story_out = inference_llava(\n",
    "            model, processor,\n",
    "            STORY_PROMPT,\n",
    "            raw_image\n",
    "        )\n",
    "\n",
    "        qgstory_out = inference_llava(\n",
    "            model, processor,\n",
    "            QGSTORY_PROMPT.format(story = story_out, number = pair_per_batch),\n",
    "            raw_image\n",
    "        )\n",
    "        \n",
    "        total_out = qgstory_out + \"\\n\"\n",
    "        SEED = random.randint(1,100)\n",
    "        print(total_out)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%m_%d_%Y-%H:%M:%S\")\n",
    "    FILENAME = f\"{IMG_ID}_{timestamp}.txt\" \n",
    "    QGSTORY_RESULT_PATH = QGSTORY_RESULT_PARENT_PATH + FILENAME\n",
    "    SEED = config[\"seed\"]\n",
    "    \n",
    "    print(total_out)\n",
    "    \n",
    "    with open(QGSTORY_RESULT_PATH,\"w\") as f:\n",
    "        f.write(total_out)\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15709d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "raw_image = Image.open(IMG_PATH)\n",
    "\n",
    "\n",
    "t_lrqg_o = datetime.now()\n",
    "lr_out = inference_llava(\n",
    "    model, processor, \n",
    "    LR_PROMPT.format(number = PAIR_NUM), \n",
    "    raw_image\n",
    ")\n",
    "\n",
    "qg_out = inference_llava(\n",
    "    model, processor,\n",
    "    QG_PROMPT.format(desc = lr_out, number = PAIR_NUM),\n",
    "    raw_image\n",
    ")\n",
    "t_lrqg_t = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "t_str8_o = datetime.now()\n",
    "str8_out = inference_llava(\n",
    "    model, processor,\n",
    "    STR8_PROMPT.format(number = PAIR_NUM),\n",
    "    raw_image\n",
    ")\n",
    "t_str8_t = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "t_qgstory_o = datetime.now()\n",
    "story_out = inference_llava(\n",
    "    model, processor,\n",
    "    STORY_PROMPT,\n",
    "    raw_image\n",
    ")\n",
    "\n",
    "qgstory_out = inference_llava(\n",
    "    model, processor,\n",
    "    QGSTORY_PROMPT.format(story = story_out, number = PAIR_NUM),\n",
    "    raw_image\n",
    ")\n",
    "t_qgstory_t = datetime.now()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%m_%d_%Y-%H:%M:%S\")\n",
    "lrqg_exec_time = exec_time(t_lrqg_o, t_lrqg_t)\n",
    "qgstory_exec_time = exec_time(t_qgstory_o, t_qgstory_t)\n",
    "str8_exec_time = exec_time(t_str8_t, t_str8_t)\n",
    "\n",
    "\n",
    "FILENAME = f\"{IMG_ID}_{timestamp}.txt\" \n",
    "LR_RESULT_PATH = LR_RESULT_PARENT_PATH + FILENAME\n",
    "QG_RESULT_PATH = QG_RESULT_PARENT_PATH + FILENAME\n",
    "STORY_RESULT_PATH = STORY_RESULT_PARENT_PATH + FILENAME\n",
    "QGSTORY_RESULT_PATH = QGSTORY_RESULT_PARENT_PATH + FILENAME\n",
    "STR8_RESULT_PATH = STR8_RESULT_PARENT_PATH + FILENAME\n",
    "\n",
    "\n",
    "with open(LR_RESULT_PATH,\"w\") as f:\n",
    "    f.write(lr_out)\n",
    "with open(QG_RESULT_PATH,\"w\") as f:\n",
    "    f.write(qg_out)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(lrqg_exec_time)\n",
    "with open(STORY_RESULT_PATH,\"w\") as f:\n",
    "    f.write(story_out)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(lrqg_exec_time)\n",
    "with open(QGSTORY_RESULT_PATH,\"w\") as f:\n",
    "    f.write(qgstory_out)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(qgstory_exec_time)\n",
    "with open(STR8_RESULT_PATH,\"w\") as f:\n",
    "    f.write(str8_out)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(str8_exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c845633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAIR_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9040aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "total_data = []\n",
    "\n",
    "for num in [\"009\", \"007\", \"005\", \"002\", \"001\"]:\n",
    "    with open(f\"sample_{num}_qgstory.txt\",\"r\") as file:\n",
    "        # Read the entire file content\n",
    "        input_string = file.read()\n",
    "\n",
    "    # Define regular expression patterns\n",
    "    pattern_question = re.compile(r'\\d+\\.\\s(.+?)\\n')\n",
    "    pattern_short_answer = re.compile(r'S\\.\\s(.+?)\\n')\n",
    "    pattern_long_answer = re.compile(r'L\\.\\s(.+?)\\n')\n",
    "\n",
    "    # Find matches using regular expressions\n",
    "    questions = pattern_question.findall(input_string)\n",
    "    short_answers = pattern_short_answer.findall(input_string)\n",
    "    long_answers = pattern_long_answer.findall(input_string)\n",
    "\n",
    "\n",
    "    # Zip the results into a list of JSON objects\n",
    "    data = [\n",
    "        {\"id\":f\"sample_{num}\",\"question\": q, \"short_answer\": sa, \"reasoned_answer\": la}\n",
    "        for q, sa, la in zip(questions, short_answers, long_answers)\n",
    "    ]\n",
    "    \n",
    "    total_data += data\n",
    "\n",
    "print(len(total_data))\n",
    "with open(f\"sdg_out.json\", 'w') as json_file:\n",
    "    json.dump(total_data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a3595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Patrick (Mistral)",
   "language": "python",
   "name": "mistral_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
