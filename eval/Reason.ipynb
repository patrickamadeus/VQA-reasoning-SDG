{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b948aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ···················································\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "import openai\n",
    "from PIL import Image\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass()\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def load_config(config_path,config_name):\n",
    "    with open(os.path.join(config_path, config_name)) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config(\"../\",\"config.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfbec1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTOID_PROMPT_PATH = config[\"prompt\"][\"eval\"][\"factoid\"]\n",
    "REASONING_PROMPT_PATH = config[\"prompt\"][\"eval\"][\"reasoning\"]\n",
    "COMPLETE_PROMPT_PATH = config[\"prompt\"][\"eval\"][\"complete\"]\n",
    "\n",
    "with open(FACTOID_PROMPT_PATH) as file:\n",
    "    FACTOID_PROMPT_TEMPLATE = file.read()\n",
    "with open(REASONING_PROMPT_PATH) as file:\n",
    "    REASONING_PROMPT_TEMPLATE = file.read()\n",
    "with open(COMPLETE_PROMPT_PATH) as file:\n",
    "    COMPLETE_PROMPT_TEMPLATE = file.read()\n",
    "    \n",
    "RESULT_JSON_PATH = config[\"eval\"][\"llava\"][\"json_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc689830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def unpack_json(json_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{json_file_path}' not found.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in '{json_file_path}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4079f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import time\n",
    "\n",
    "unpacked_results = unpack_json(RESULT_JSON_PATH+\"LLaVa_3W_split_003.json\")\n",
    "ids, factoid_scores, reason_scores = [],[],[]\n",
    "raw_scores = []\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "fact_sys_template = (\n",
    "    \"You are a helpful evaluator that is responsible to grade answer of a question based on the description\"\n",
    ")\n",
    "fact_sys_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "fact_human_prompt = HumanMessagePromptTemplate.from_template(FACTOID_PROMPT_TEMPLATE)\n",
    "fact_prompt = ChatPromptTemplate.from_messages(\n",
    "    [fact_sys_prompt, fact_human_prompt]\n",
    ")\n",
    "\n",
    "reason_sys_template = (\n",
    "    \"You are a helpful evaluator that is responsible to grade answer of a question based on the description\"\n",
    ")\n",
    "reason_sys_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "reason_human_prompt = HumanMessagePromptTemplate.from_template(REASONING_PROMPT_TEMPLATE)\n",
    "reason_prompt = ChatPromptTemplate.from_messages(\n",
    "    [reason_sys_prompt, reason_human_prompt]\n",
    ")\n",
    "\n",
    "# sys_template = (\n",
    "#     \"You are an NLP expert that is responsible to grade answer & reasoning of a question based on the description\"\n",
    "# )\n",
    "# sys_prompt = SystemMessagePromptTemplate.from_template(sys_template)\n",
    "# msg_prompt = HumanMessagePromptTemplate.from_template(COMPLETE_PROMPT_TEMPLATE)\n",
    "# complete_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [sys_prompt, msg_prompt]\n",
    "# )\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for sample in tqdm(unpacked_results):\n",
    "        curr_id = sample[\"id\"]\n",
    "        curr_desc = sample[\"description\"]\n",
    "        curr_q = sample[\"question\"]\n",
    "        curr_sa = sample[\"short_answer\"]\n",
    "        curr_ra = sample[\"reasoned_answer\"]\n",
    "        \n",
    "#         complete_res = chat(\n",
    "#             complete_prompt.format_prompt(\n",
    "#                 description = curr_desc,\n",
    "#                 question = curr_q,\n",
    "#                 answer = curr_sa,\n",
    "#                 reason = curr_ra\n",
    "#             ).to_messages()\n",
    "#         )\n",
    "        \n",
    "        sa_res = chat(\n",
    "            fact_prompt.format_prompt(\n",
    "                description = curr_desc,\n",
    "                question = curr_q,\n",
    "                answer = curr_sa\n",
    "            ).to_messages()\n",
    "        )\n",
    "\n",
    "        ra_res = chat(\n",
    "            reason_prompt.format_prompt(\n",
    "                description = curr_desc,\n",
    "                question = curr_q,\n",
    "                reason = curr_ra\n",
    "            ).to_messages()\n",
    "        )\n",
    "\n",
    "        ids.append(curr_id)\n",
    "#         raw_scores.append(complete_res.content)\n",
    "        factoid_scores.append(sa_res.content)\n",
    "        reason_scores.append(ra_res.content)\n",
    "    \n",
    "    with open(\"price_log.txt\", \"w\") as price_log_file:\n",
    "        price_log_file.write(str(cb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2bdc3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "with open(\"price_log.txt\", \"w\") as price_log_file:\n",
    "    price_log_file.write(str(dt.now())+\"\\n\\n\")\n",
    "    price_log_file.write(str(cb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78d2b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs,logics,clears,details,irrels,plauss=[],[],[],[],[],[]\n",
    "\n",
    "for ID, fs, rs in zip(ids,factoid_scores, reason_scores):\n",
    "    logic, clear, detail, irrel, plaus = (int(s) for s in rs.split(\";\"))\n",
    "    accs.append(int(fs))\n",
    "    logics.append(logic)\n",
    "    clears.append(clear)\n",
    "    details.append(detail)\n",
    "    irrels.append(irrel)\n",
    "    plauss.append(plaus)\n",
    "    \n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"id\" : i,\n",
    "        \"accuracy\": a,\n",
    "        \"logic\" : l,\n",
    "        \"clarity\" : c,\n",
    "        \"detail\" : d,\n",
    "        \"irrelevance\" : ir,\n",
    "        \"plausibility\" : p\n",
    "    }\n",
    "    for i,a,l,c,d,ir,p in zip(ids,accs,logics,clears,details,irrels,plauss)\n",
    "]\n",
    "\n",
    "with open(\"Eval_LLaVa_3W_split_003.json\", 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a61747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Patrick (eval)",
   "language": "python",
   "name": "patrick_eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
